{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn-Together: Classifiers\n",
    "\n",
    "*Experimented with different classifiers; also scaled training/test data*\n",
    "\n",
    "* https://www.kaggle.com/kwabenantim/forest-cover-stacking-multiple-classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, test_data, test_ids, file_name):\n",
    "    predictions = model.predict(test_data)\n",
    "    output = pd.DataFrame({\"Id\": test_ids, \"Cover_Type\": predictions})\n",
    "    output.to_csv(\"submissions/\"+ file_name +\".csv\", index=False)\n",
    "    print(\"Submission generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:48: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:49: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "submission_ex = pd.read_csv(\"assets/learn-together/sample_submission.csv\")\n",
    "train_df = pd.read_csv(\"assets/learn-together/train.csv\")\n",
    "test_df = pd.read_csv(\"assets/learn-together/test.csv\")\n",
    "\n",
    "for X in [train_df, test_df]:\n",
    "    X['Hydro_Elevation_diff'] = (X['Elevation'] - \n",
    "                                 X['Vertical_Distance_To_Hydrology'])\n",
    "\n",
    "    X['Hydro_Fire_sum'] = (X['Horizontal_Distance_To_Hydrology'] + \n",
    "                           X['Horizontal_Distance_To_Fire_Points'])\n",
    "\n",
    "    X['Hydro_Fire_diff'] = (X['Horizontal_Distance_To_Hydrology'] - \n",
    "                            X['Horizontal_Distance_To_Fire_Points']).abs()\n",
    "\n",
    "    X['Hydro_Road_sum'] = (X['Horizontal_Distance_To_Hydrology'] +\n",
    "                           X['Horizontal_Distance_To_Roadways'])\n",
    "\n",
    "    X['Hydro_Road_diff'] = (X['Horizontal_Distance_To_Hydrology'] -\n",
    "                            X['Horizontal_Distance_To_Roadways']).abs()\n",
    "\n",
    "    X['Road_Fire_sum'] = (X['Horizontal_Distance_To_Roadways'] + \n",
    "                          X['Horizontal_Distance_To_Fire_Points'])\n",
    "\n",
    "    X['Road_Fire_diff'] = (X['Horizontal_Distance_To_Roadways'] - \n",
    "                           X['Horizontal_Distance_To_Fire_Points']).abs()\n",
    "    \n",
    "target = [\"Cover_Type\"]\n",
    "cols_to_drop = [\"Id\", \"Soil_Type7\", \"Soil_Type15\", \"Cover_Type\"]\n",
    "\n",
    "train = train_df.copy()\n",
    "test = test_df.copy()\n",
    "\n",
    "y = train[target]\n",
    "train.drop(columns=cols_to_drop, inplace=True)\n",
    "test_ids = test[\"Id\"]\n",
    "test.drop(columns=[\"Id\", \"Soil_Type7\", \"Soil_Type15\"], inplace=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train,\n",
    "                                                  y, \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=seed)\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape\n",
    "\n",
    "# NEW\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.transform(X_val)\n",
    "test = sc.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: adaboostclassifier (1/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   27.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: extratreesclassifier (2/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier3: lgbmclassifier (3/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   21.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier4: randomforestclassifier (4/4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit completed.\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(n_estimators=200,\n",
    "                            base_estimator=DecisionTreeClassifier(\n",
    "                                min_samples_leaf=2,\n",
    "                                random_state=seed),\n",
    "                            random_state=seed)\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=300,\n",
    "                              min_samples_leaf=2,\n",
    "                              min_samples_split=2,\n",
    "                              max_depth=50,\n",
    "                              random_state=seed,\n",
    "                              n_jobs=-1)\n",
    "\n",
    "lg = LGBMClassifier(n_estimators=300,\n",
    "                        num_leaves=128,\n",
    "                        verbosity=-1,\n",
    "                        random_state=seed,\n",
    "                        n_jobs=1)\n",
    "\n",
    "best_rf_params = {'bootstrap': False,\n",
    " 'max_depth': 50,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 300}\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=best_rf_params[\"n_estimators\"],\n",
    "                            max_depth=best_rf_params[\"max_depth\"],\n",
    "                            min_samples_leaf=best_rf_params[\"min_samples_leaf\"],\n",
    "                            min_samples_split=best_rf_params[\"min_samples_split\"],\n",
    "                            bootstrap=False,\n",
    "                            random_state=seed,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "models = [ab, et, lg, rf]\n",
    "\n",
    "stack = StackingCVClassifier(classifiers=models,\n",
    "                             meta_classifier=rf,\n",
    "                             cv=5,\n",
    "                             stratify=True,\n",
    "                             shuffle=True,\n",
    "                             use_probas=True,\n",
    "                             use_features_in_secondary=True,\n",
    "                             verbose=1,\n",
    "                             random_state=seed,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "stack = stack.fit(X_train, y_train)\n",
    "\n",
    "print(\"Fit completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = stack.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9110449735449735"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_val, predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission generated.\n"
     ]
    }
   ],
   "source": [
    "generate_submission(stack, test, test_ids, \"4_stacked_classifiers_fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
