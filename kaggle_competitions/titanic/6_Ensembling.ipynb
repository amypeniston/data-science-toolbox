{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold, RandomizedSearchCV, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score\n",
    "\n",
    "sns.set()\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "SEED = 42\n",
    "\n",
    "train_ = pd.read_csv(\"assets/train.csv\")\n",
    "test_ = pd.read_csv(\"assets/test.csv\")\n",
    "\n",
    "train = train_.copy()\n",
    "test = test_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: {'PassengerId', 'Age', 'Parch', 'Pclass', 'Survived', 'Fare', 'SibSp'}\n",
      "Categorical Features: {'Sex', 'Name', 'Cabin', 'Ticket', 'Embarked'}\n"
     ]
    }
   ],
   "source": [
    "num_features = set([c for c in train.columns if train[c].dtype != \"object\"])\n",
    "cat_features = set([c for c in train.columns if c not in num_features])\n",
    "print(\"Numerical Features: {}\\nCategorical Features: {}\".format(num_features, cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_rare_titles(df):\n",
    "    title = df[\"Title\"]\n",
    "    if title in [\"Capt\", \"Col\", \"Don\", \"Jonkheer\", \"Major\", \"Sir\", \"Rev\"]:\n",
    "        return \"Mr\"\n",
    "    elif title in [\"Mme\", \"th\", \"Lady\", \"Dona\"]:\n",
    "        return 'Mrs'\n",
    "    elif title in [\"Mlle\", \"Ms\"]:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if df['Sex']=='Male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "    \n",
    "    \n",
    "def substrings_in_string(big_string, substrings):\n",
    "    if pd.isna(big_string):\n",
    "        return \"Unknown\"\n",
    "    for substring in substrings:\n",
    "        if big_string.find(substring) != -1:\n",
    "            if substring == \"T\":\n",
    "                return \"A\"\n",
    "            else:\n",
    "                return substring\n",
    "            \n",
    "def engineer_numerical_features(df):\n",
    "    temp = df.copy()\n",
    "    \n",
    "    # temp[\"Age\"].fillna(temp[\"Age\"].mean(), inplace=True)\n",
    "    mean = temp[\"Age\"].mean()\n",
    "    std = temp[\"Age\"].std()\n",
    "    is_null = temp[\"Age\"].isnull().sum()\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size=is_null)\n",
    "    ages = temp[\"Age\"].copy()\n",
    "    ages[np.isnan(ages)] = rand_age\n",
    "    temp[\"Age\"] = ages\n",
    "    temp[\"Age\"] = temp[\"Age\"].astype(int)\n",
    "\n",
    "    temp.loc[temp[\"Age\"] <= 18, \"Age\"] = 0\n",
    "    temp.loc[(temp[\"Age\"] > 18) & (temp[\"Age\"] <= 23), \"Age\"] = 1\n",
    "    temp.loc[(temp[\"Age\"] > 23) & (temp[\"Age\"] <= 28), \"Age\"] = 2\n",
    "    temp.loc[(temp[\"Age\"] > 28) & (temp[\"Age\"] <= 34), \"Age\"] = 3\n",
    "    temp.loc[(temp[\"Age\"] > 34) & (temp[\"Age\"] <= 44), \"Age\"] = 4\n",
    "    temp.loc[(temp[\"Age\"] > 44), \"Age\"] = 5\n",
    "\n",
    "    #temp[\"Fare\"].fillna(0, inplace=True)\n",
    "    mean = temp[\"Fare\"].mean()\n",
    "    std = temp[\"Fare\"].std()\n",
    "    is_null = temp[\"Fare\"].isnull().sum()\n",
    "    rand_fare = np.random.randint(mean - std, mean + std, size=is_null)\n",
    "    fares = temp[\"Fare\"].copy()\n",
    "    fares[np.isnan(fares)] = rand_fare\n",
    "    temp[\"Fare\"] = fares\n",
    "    \n",
    "    # Need to fix this binning:\n",
    "\n",
    "    temp.loc[ temp[\"Fare\"] <= 7.775, \"Fare\"] = 0\n",
    "    temp.loc[(temp[\"Fare\"] > 7.775) & (temp[\"Fare\"] <= 8.662), \"Fare\"] = 1\n",
    "    temp.loc[(temp[\"Fare\"] > 8.662) & (temp[\"Fare\"] <= 14.454), \"Fare\"] = 2\n",
    "    temp.loc[(temp[\"Fare\"] > 14.454) & (temp[\"Fare\"] <= 26), \"Fare\"] = 3\n",
    "    temp.loc[(temp[\"Fare\"] > 26) & (temp[\"Fare\"] <= 52.369), \"Fare\"] = 4\n",
    "    temp.loc[ temp[\"Fare\"] > 52.369, \"Fare\"] = 5\n",
    "    temp[\"Fare\"] = temp[\"Fare\"].astype(int)\n",
    "    \n",
    "    family_size = temp[\"SibSp\"] + temp[\"Parch\"]\n",
    "    temp[\"FamilySize\"] = family_size\n",
    "    \n",
    "    fare_per_person = temp[\"Fare\"] / (temp[\"FamilySize\"] + 1)\n",
    "    temp[\"FarePerPerson\"] = fare_per_person\n",
    "    \n",
    "    age_class = temp[\"Age\"] * temp[\"Pclass\"]\n",
    "    temp[\"AgeClass\"] = age_class\n",
    "    \n",
    "    return temp\n",
    "\n",
    "def engineer_categorical_features(df):\n",
    "    temp = df.copy()\n",
    "    \n",
    "    temp[\"Embarked\"].fillna(temp[\"Embarked\"].mode()[0], inplace=True)\n",
    "    \n",
    "    titles = temp[\"Name\"].str.split(', ', expand=True)[1].str.split(\". \", expand=True)[0]\n",
    "    temp[\"Title\"] = titles\n",
    "    temp[\"Title\"] = temp.apply(replace_rare_titles, axis=1)\n",
    "    \n",
    "    #deck = temp[\"Cabin\"].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "    temp[\"Cabin\"] = temp[\"Cabin\"].fillna(\"U0\")\n",
    "    deck = temp[\"Cabin\"].map(lambda x: x[0])\n",
    "    temp[\"Deck\"] = deck\n",
    "    decks = {\"A\": 1, \"T\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "    temp[\"Deck\"] = temp[\"Deck\"].map(decks)\n",
    "    temp[\"Deck\"] = temp[\"Deck\"].astype(int)\n",
    "    \n",
    "#     genders = {\"male\": 0, \"female\": 1}\n",
    "#     temp[\"Sex\"] = temp[\"Sex\"].map(genders)\n",
    "    \n",
    "#     ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "#     temp[\"Embarked\"] = temp[\"Embarked\"].map(ports)\n",
    "    \n",
    "    one_hot_cols = [\"Title\", \"Sex\", \"Embarked\"]\n",
    "    \n",
    "    for o in one_hot_cols:\n",
    "        dummies = pd.get_dummies(temp[o], prefix=o)\n",
    "        temp = pd.concat([temp, dummies], axis=1)\n",
    "    \n",
    "    temp.drop(columns=list(cat_features) + [\"Title\", \"Sex\", \"Embarked\", \"PassengerId\"], inplace=True)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = engineer_numerical_features(train_)\n",
    "test = engineer_numerical_features(test_)\n",
    "train = engineer_categorical_features(train)\n",
    "test = engineer_categorical_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "y = X.pop(\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "**RandomizedSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "rf_random_param = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=rf_random_param, n_iter=100, cv=kfold, random_state=SEED, n_jobs=4)\n",
    "\n",
    "# rf_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_random.best_params_\n",
    "# rf_random.best_score_ # 0.8305274971941639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_random.best_params_\n",
    "\n",
    "rf_random_p = {'n_estimators': 1000,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 100,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_param = {'n_estimators': [600, 800, 1000, 1200],\n",
    "     'min_samples_split': [3, 5, 7],\n",
    "     'min_samples_leaf': [3, 4, 5, 6],\n",
    "     'max_features': ['auto'],\n",
    "     'max_depth': [80, 90, 100, 110],\n",
    "     'bootstrap': [True]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=SEED)    \n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=rf_grid_param, cv=kfold, n_jobs=4)\n",
    "\n",
    "# rf_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_grid.best_params_\n",
    "# rf_random.best_score_ # 0.8305274971941639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_grid.best_params_\n",
    "\n",
    "rf_grid_p = {'bootstrap': True,\n",
    " 'max_depth': 80,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 4,\n",
    " 'min_samples_split': 3,\n",
    " 'n_estimators': 1000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf_baseline = RandomForestClassifier(random_state=SEED)\n",
    "rf_baseline.fit(X, y)\n",
    "rf_baseline_results = cross_validate(rf_baseline, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "rf_random = RandomForestClassifier(random_state=SEED, **rf_random_p)\n",
    "rf_random.fit(X, y)\n",
    "rf_random_results = cross_validate(rf_random, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "rf_grid = RandomForestClassifier(random_state=SEED, **rf_grid_p)\n",
    "rf_grid.fit(X, y)\n",
    "rf_grid_results = cross_validate(rf_grid, X, y, cv=kfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.7958110665805609\n",
      "Random: 0.8238825485754775\n",
      "Grid: 0.8238825485754775\n"
     ]
    }
   ],
   "source": [
    "rf_baseline_score = rf_baseline_results[\"test_score\"].mean()\n",
    "rf_random_score = rf_random_results[\"test_score\"].mean()\n",
    "rf_grid_score = rf_grid_results[\"test_score\"].mean()\n",
    "print(\"Baseline: {}\\nRandom: {}\\nGrid: {}\".format(rf_baseline_score, rf_random_score, rf_grid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline: 0.8100558659217877\n",
    "Random: 0.8156424581005587\n",
    "Grid: 0.8100558659217877"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomizedSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=4,\n",
       "          param_distributions={'loss': ['deviance'], 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'learning_rate': [0.15, 0.1, 0.05, 0.01], 'max_depth': [2, 4, 6, 8], 'min_samples_leaf': [75, 100, 125, 150], 'max_features': [0.5, 0.3, 0.1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=SEED)\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "gbc_random_param = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : n_estimators,\n",
    "              'learning_rate': [0.15, 0.1, 0.05, 0.01],\n",
    "              'max_depth': [2, 4, 6, 8],\n",
    "              'min_samples_leaf': [75, 100, 125, 150],\n",
    "              'max_features': [0.5, 0.3, 0.1] \n",
    "              }\n",
    "\n",
    "gbc_random = RandomizedSearchCV(estimator=gbc, param_distributions=gbc_random_param, n_iter=100, cv=kfold, random_state=SEED, n_jobs=4)\n",
    "\n",
    "gbc_random.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc_random.best_params_\n",
    "# gbc_random.best_score_ # 0.8338945005611672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbc_random.best_params_\n",
    "\n",
    "gbc_random_p = {'n_estimators': 1800,\n",
    " 'min_samples_leaf': 150,\n",
    " 'max_features': 0.5,\n",
    " 'max_depth': 8,\n",
    " 'loss': 'deviance',\n",
    " 'learning_rate': 0.15}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid={'loss': ['deviance'], 'n_estimators': [1600, 1800, 2000, 2200], 'learning_rate': [0.2, 0.15, 0.1, 0.05], 'max_depth': [6, 8, 10], 'min_samples_leaf': [125, 150, 175], 'max_features': [0.75, 0.5, 0.25]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=SEED)\n",
    "gbc_grid_param = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [1600, 1800, 2000, 2200],\n",
    "              'learning_rate': [0.2, 0.15, 0.1, 0.05],\n",
    "              'max_depth': [6, 8, 10],\n",
    "              'min_samples_leaf': [125, 150, 175],\n",
    "              'max_features': [0.75, 0.5, 0.25] \n",
    "              }\n",
    "\n",
    "gbc_grid = GridSearchCV(gbc, param_grid=gbc_grid_param, cv=kfold, scoring=\"accuracy\", n_jobs=4)\n",
    "\n",
    "# gbc_grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.15,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 0.75,\n",
       " 'min_samples_leaf': 150,\n",
       " 'n_estimators': 1600}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gbc_grid.best_params_\n",
    "# gbc_grid.best_score_ # 0.8159371492704826 w/o randomizedsearch, 0.8361391694725028 after randomizedsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc_grid.best_params_\n",
    "\n",
    "gbc_grid_p = {'learning_rate': 0.15,\n",
    " 'loss': 'deviance',\n",
    " 'max_depth': 6,\n",
    " 'max_features': 0.75,\n",
    " 'min_samples_leaf': 150,\n",
    " 'n_estimators': 1600}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_baseline = GradientBoostingClassifier(random_state=SEED)\n",
    "gbc_baseline.fit(X, y)\n",
    "gbc_baseline_results = cross_validate(gbc_baseline, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "gbc_random = GradientBoostingClassifier(random_state=SEED, **gbc_random_p)\n",
    "gbc_random.fit(X, y)\n",
    "gbc_random_results = cross_validate(gbc_random, X, y, cv=kfold, return_train_score=True)\n",
    "\n",
    "gbc_grid = GradientBoostingClassifier(random_state=SEED, **gbc_grid_p)\n",
    "gbc_grid.fit(X, y)\n",
    "gbc_grid_results = cross_validate(gbc_grid, X, y, cv=kfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.8093196755641472\n",
      "Random: 0.8339319955727152\n",
      "Grid: 0.8361855345811581\n"
     ]
    }
   ],
   "source": [
    "gbc_baseline_score = gbc_baseline_results[\"test_score\"].mean()\n",
    "gbc_random_score = gbc_random_results[\"test_score\"].mean()\n",
    "gbc_grid_score = gbc_grid_results[\"test_score\"].mean()\n",
    "print(\"Baseline: {}\\nRandom: {}\\nGrid: {}\".format(gbc_baseline_score, gbc_random_score, gbc_grid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomizedSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "          error_score='raise-deprecating',\n",
       "          estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=100, n_jobs=4,\n",
       "          param_distributions={'max_depth': [None], 'max_features': [1, 3, 5, 7, 10], 'min_samples_split': [2, 3, 5, 7, 10], 'min_samples_leaf': [1, 3, 5, 10], 'bootstrap': [False], 'n_estimators': [100, 300, 500, 700, 900], 'criterion': ['gini']},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(random_state=SEED)\n",
    "\n",
    "etc_random_param = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 5, 7, 10],\n",
    "              \"min_samples_split\": [2, 3, 5, 7, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 5, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100, 300, 500, 700, 900],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "etc_random = RandomizedSearchCV(estimator=etc, param_distributions=etc_random_param, n_iter=100, cv=kfold, n_jobs=4, random_state=SEED)\n",
    "\n",
    "#etc_random.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8316498316498316"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etc_random.best_params_\n",
    "# etc_random.best_score_ # 0.8316498316498316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 900,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 5,\n",
       " 'max_features': 7,\n",
       " 'max_depth': None,\n",
       " 'criterion': 'gini',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etc_random.best_params_\n",
    "\n",
    "etc_random_p = {'n_estimators': 900,\n",
    " 'min_samples_split': 10,\n",
    " 'min_samples_leaf': 5,\n",
    " 'max_features': 7,\n",
    " 'max_depth': None,\n",
    " 'criterion': 'gini',\n",
    " 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [None], 'max_features': [6, 8, 10], 'min_samples_split': [6, 8, 10, 12], 'min_samples_leaf': [3, 5, 7], 'bootstrap': [False], 'n_estimators': [800, 1000, 1200], 'criterion': ['gini']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(random_state=SEED)\n",
    "\n",
    "etc_grid_param = {\"max_depth\": [None],\n",
    "              \"max_features\": [6, 8, 10],\n",
    "              \"min_samples_split\": [6, 8, 10, 12],\n",
    "              \"min_samples_leaf\": [3, 5, 7],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[800, 1000, 1200],\n",
    "              \"criterion\": [\"gini\"]}\n",
    "\n",
    "etc_grid = GridSearchCV(etc, param_grid=etc_grid_param, scoring=\"accuracy\", cv=kfold, n_jobs=4)\n",
    "\n",
    "#etc_grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835016835016835"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etc_grid.best_params_\n",
    "# etc_grid.best_score_ # 0.835016835016835"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 6,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 12,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# etc_grid.best_params_\n",
    "\n",
    "etc_grid_p = {'bootstrap': False,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': None,\n",
    " 'max_features': 6,\n",
    " 'min_samples_leaf': 5,\n",
    " 'min_samples_split': 12,\n",
    " 'n_estimators': 1000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=80, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=4, min_samples_split=3,\n",
       "            min_weig..._dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_ensemble = VotingClassifier(estimators=[(\"rf\", rf_grid), \n",
    "                                               (\"gbc\", gbc_grid), \n",
    "                                               (\"etc\", etc_grid)], voting=\"soft\", n_jobs=-1)\n",
    "# voting_ensemble.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = voting_ensemble.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_submission(filename, yhat, save=False):\n",
    "    submission_df = pd.DataFrame(columns=[\"PassengerId\", \"Survived\"])\n",
    "    submission_df[\"PassengerId\"] = test_[\"PassengerId\"]\n",
    "    submission_df[\"Survived\"] = yhat\n",
    "    if save:\n",
    "        submission_df.to_csv(\"submissions/\"+filename, header=True, index=False)\n",
    "    return submission_df\n",
    "\n",
    "filename = \"ensemble_model_rf_gbc_etc.csv\"\n",
    "submission = generate_submission(filename, yhat, False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat2 = gbc_grid.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"gbc_grid.csv\"\n",
    "submission = generate_submission(filename, yhat2, True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
