{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold, RandomizedSearchCV, GridSearchCV, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, accuracy_score\n",
    "\n",
    "sns.set()\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "SEED = 42\n",
    "\n",
    "train_ = pd.read_csv(\"assets/train.csv\")\n",
    "test_ = pd.read_csv(\"assets/test.csv\")\n",
    "\n",
    "train = train_.copy()\n",
    "test = test_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Features: {'PassengerId', 'Parch', 'SibSp', 'Fare', 'Pclass', 'Survived', 'Age'}\n",
      "Categorical Features: {'Name', 'Sex', 'Embarked', 'Ticket', 'Cabin'}\n"
     ]
    }
   ],
   "source": [
    "num_features = set([c for c in train.columns if train[c].dtype != \"object\"])\n",
    "cat_features = set([c for c in train.columns if c not in num_features])\n",
    "print(\"Numerical Features: {}\\nCategorical Features: {}\".format(num_features, cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_rare_titles(df):\n",
    "    title = df[\"Title\"]\n",
    "    if title in [\"Capt\", \"Col\", \"Don\", \"Jonkheer\", \"Major\", \"Sir\", \"Rev\"]:\n",
    "        return \"Mr\"\n",
    "    elif title in [\"Mme\", \"th\", \"Lady\", \"Dona\"]:\n",
    "        return 'Mrs'\n",
    "    elif title in [\"Mlle\", \"Ms\"]:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if df['Sex']=='Male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title\n",
    "    \n",
    "    \n",
    "def substrings_in_string(big_string, substrings):\n",
    "    if pd.isna(big_string):\n",
    "        return \"Unknown\"\n",
    "    for substring in substrings:\n",
    "        if big_string.find(substring) != -1:\n",
    "            if substring == \"T\":\n",
    "                return \"A\"\n",
    "            else:\n",
    "                return substring\n",
    "            \n",
    "def engineer_numerical_features(df):\n",
    "    temp = df.copy()\n",
    "    \n",
    "    # temp[\"Age\"].fillna(temp[\"Age\"].mean(), inplace=True)\n",
    "    mean = temp[\"Age\"].mean()\n",
    "    std = temp[\"Age\"].std()\n",
    "    is_null = temp[\"Age\"].isnull().sum()\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size=is_null)\n",
    "    ages = temp[\"Age\"].copy()\n",
    "    ages[np.isnan(ages)] = rand_age\n",
    "    temp[\"Age\"] = ages\n",
    "    temp[\"Age\"] = temp[\"Age\"].astype(int)\n",
    "\n",
    "    temp.loc[temp[\"Age\"] <= 18, \"Age\"] = 0\n",
    "    temp.loc[(temp[\"Age\"] > 18) & (temp[\"Age\"] <= 23), \"Age\"] = 1\n",
    "    temp.loc[(temp[\"Age\"] > 23) & (temp[\"Age\"] <= 28), \"Age\"] = 2\n",
    "    temp.loc[(temp[\"Age\"] > 28) & (temp[\"Age\"] <= 34), \"Age\"] = 3\n",
    "    temp.loc[(temp[\"Age\"] > 34) & (temp[\"Age\"] <= 44), \"Age\"] = 4\n",
    "    temp.loc[(temp[\"Age\"] > 44), \"Age\"] = 5\n",
    "\n",
    "    #temp[\"Fare\"].fillna(0, inplace=True)\n",
    "    mean = temp[\"Fare\"].mean()\n",
    "    std = temp[\"Fare\"].std()\n",
    "    is_null = temp[\"Fare\"].isnull().sum()\n",
    "    rand_fare = np.random.randint(mean - std, mean + std, size=is_null)\n",
    "    fares = temp[\"Fare\"].copy()\n",
    "    fares[np.isnan(fares)] = rand_fare\n",
    "    temp[\"Fare\"] = fares\n",
    "    \n",
    "    # Need to fix this binning:\n",
    "\n",
    "    temp.loc[ temp[\"Fare\"] <= 7.775, \"Fare\"] = 0\n",
    "    temp.loc[(temp[\"Fare\"] > 7.775) & (temp[\"Fare\"] <= 8.662), \"Fare\"] = 1\n",
    "    temp.loc[(temp[\"Fare\"] > 8.662) & (temp[\"Fare\"] <= 14.454), \"Fare\"] = 2\n",
    "    temp.loc[(temp[\"Fare\"] > 14.454) & (temp[\"Fare\"] <= 26), \"Fare\"] = 3\n",
    "    temp.loc[(temp[\"Fare\"] > 26) & (temp[\"Fare\"] <= 52.369), \"Fare\"] = 4\n",
    "    temp.loc[ temp[\"Fare\"] > 52.369, \"Fare\"] = 5\n",
    "    temp[\"Fare\"] = temp[\"Fare\"].astype(int)\n",
    "    \n",
    "    family_size = temp[\"SibSp\"] + temp[\"Parch\"]\n",
    "    temp[\"FamilySize\"] = family_size\n",
    "    \n",
    "    fare_per_person = temp[\"Fare\"] / (temp[\"FamilySize\"] + 1)\n",
    "    temp[\"FarePerPerson\"] = fare_per_person\n",
    "    \n",
    "    age_class = temp[\"Age\"] * temp[\"Pclass\"]\n",
    "    temp[\"AgeClass\"] = age_class\n",
    "    \n",
    "    return temp\n",
    "\n",
    "def engineer_categorical_features(df):\n",
    "    temp = df.copy()\n",
    "    \n",
    "    temp[\"Embarked\"].fillna(temp[\"Embarked\"].mode()[0], inplace=True)\n",
    "    \n",
    "    titles = temp[\"Name\"].str.split(', ', expand=True)[1].str.split(\". \", expand=True)[0]\n",
    "    temp[\"Title\"] = titles\n",
    "    temp[\"Title\"] = temp.apply(replace_rare_titles, axis=1)\n",
    "    \n",
    "    #deck = temp[\"Cabin\"].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "    temp[\"Cabin\"] = temp[\"Cabin\"].fillna(\"U0\")\n",
    "    deck = temp[\"Cabin\"].map(lambda x: x[0])\n",
    "    temp[\"Deck\"] = deck\n",
    "    decks = {\"A\": 1, \"T\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "    temp[\"Deck\"] = temp[\"Deck\"].map(decks)\n",
    "    temp[\"Deck\"] = temp[\"Deck\"].astype(int)\n",
    "    \n",
    "#     genders = {\"male\": 0, \"female\": 1}\n",
    "#     temp[\"Sex\"] = temp[\"Sex\"].map(genders)\n",
    "    \n",
    "#     ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "#     temp[\"Embarked\"] = temp[\"Embarked\"].map(ports)\n",
    "    \n",
    "    one_hot_cols = [\"Title\", \"Sex\", \"Embarked\"]\n",
    "    \n",
    "    for o in one_hot_cols:\n",
    "        dummies = pd.get_dummies(temp[o], prefix=o)\n",
    "        temp = pd.concat([temp, dummies], axis=1)\n",
    "    \n",
    "    temp.drop(columns=list(cat_features) + [\"Title\", \"Sex\", \"Embarked\", \"PassengerId\"], inplace=True)\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = engineer_numerical_features(train_)\n",
    "test = engineer_numerical_features(test_)\n",
    "train = engineer_categorical_features(train)\n",
    "test = engineer_categorical_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_z.copy()\n",
    "y = X.pop(\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_baseline = RandomForestClassifier(random_state=SEED)\n",
    "rf_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "rf_random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=rf_random_grid, n_iter=100, cv=3, random_state=SEED, n_jobs=2)\n",
    "\n",
    "# rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_random.best_params_\n",
    "\n",
    "rf_random_p = {'n_estimators': 200,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 80,\n",
    " 'bootstrap': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [200, 300, 400, 500, 600], 'min_samples_split': [3, 5, 7], 'min_samples_leaf': [4, 5, 6, 7], 'max_features': ['auto'], 'max_depth': [40, 50, 60, 70, 80], 'bootstrap': [True]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_param_grid = {'n_estimators': [200, 300, 400, 500, 600],\n",
    "     'min_samples_split': [3, 5, 7],\n",
    "     'min_samples_leaf': [4, 5, 6, 7],\n",
    "     'max_features': ['auto'],\n",
    "     'max_depth': [40, 50, 60, 70, 80],\n",
    "     'bootstrap': [True]}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=SEED)    \n",
    "rf_grid = GridSearchCV(estimator=rf, param_grid=rf_param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "# rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_grid.best_params_\n",
    "\n",
    "# rf_grid_p = {'bootstrap': True,\n",
    "#  'max_depth': 40,\n",
    "#  'max_features': 'auto',\n",
    "#  'min_samples_leaf': 6,\n",
    "#  'min_samples_split': 3,\n",
    "#  'n_estimators': 600}\n",
    "\n",
    "rf_param_p = {'bootstrap': True,\n",
    " 'max_depth': 40,\n",
    " 'max_features': 'auto',\n",
    " 'min_samples_leaf': 4,\n",
    " 'min_samples_split': 3,\n",
    " 'n_estimators': 400}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PROGRAMS\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=6, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_baseline = RandomForestClassifier(random_state=SEED)\n",
    "rf_baseline.fit(X_train, y_train)\n",
    "\n",
    "rf_random = RandomForestClassifier(random_state=SEED, **rf_random_p)\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_grid = RandomForestClassifier(random_state=SEED, **rf_grid_p)\n",
    "rf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.8100558659217877\n",
      "Random: 0.8156424581005587\n",
      "Grid: 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "rf_baseline_score = rf_baseline.score(X_test, y_test)\n",
    "rf_random_score = rf_random.score(X_test, y_test)\n",
    "rf_grid_score = rf_grid.score(X_test, y_test)\n",
    "print(\"Baseline: {}\\nRandom: {}\\nGrid: {}\".format(rf_baseline_score, rf_random_score, rf_grid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=SEED)\n",
    "gbc_param_grid = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [100, 200, 300],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 8],\n",
    "              'min_samples_leaf': [100, 150],\n",
    "              'max_features': [0.3, 0.1] \n",
    "              }\n",
    "\n",
    "gbc_grid = GridSearchCV(gbc, param_grid = gbc_param_grid, cv=3, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "\n",
    "gbc_grid.fit(X_train, y_train)\n",
    "\n",
    "gbc_grid_best_estimator = gbc_grid.best_estimator_\n",
    "gbc_grid_best_score = gbc_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbc_grid.best_params_\n",
    "\n",
    "gbc_grid_p = {'learning_rate': 0.1,\n",
    " 'loss': 'deviance',\n",
    " 'max_depth': 4,\n",
    " 'max_features': 0.3,\n",
    " 'min_samples_leaf': 100,\n",
    " 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=8,\n",
       "              max_features=0.3, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=100, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "              n_iter_no_change=None, presort='auto', random_state=42,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_baseline = GradientBoostingClassifier(random_state=SEED)\n",
    "gbc_baseline.fit(X_train, y_train)\n",
    "\n",
    "gbc_grid = GradientBoostingClassifier(random_state=SEED, **gbc_grid_p)\n",
    "gbc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.8324022346368715\n",
      "Grid: 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "gbc_baseline_score = gbc_baseline.score(X_test, y_test)\n",
    "gbc_grid_score = gbc_grid.score(X_test, y_test)\n",
    "print(\"Baseline: {}\\nGrid: {}\".format(gbc_baseline_score, gbc_grid_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(random_state=SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=6, min_samples_split=3,\n",
       "            min_weig..._dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1))],\n",
       "         flatten_transform=None, n_jobs=-1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_ensemble = VotingClassifier(estimators=[(\"rf\", rf_grid), (\"gbc\", gbc_grid)], voting=\"soft\", n_jobs=-1)\n",
    "voting_ensemble.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = voting_ensemble.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_submission(filename, yhat, save=False):\n",
    "    submission_df = pd.DataFrame(columns=[\"PassengerId\", \"Survived\"])\n",
    "    submission_df[\"PassengerId\"] = test_[\"PassengerId\"]\n",
    "    submission_df[\"Survived\"] = yhat\n",
    "    if save:\n",
    "        submission_df.to_csv(\"submissions/\"+filename, header=True, index=False)\n",
    "    return submission_df\n",
    "\n",
    "filename = \"ensemble_model_2.csv\"\n",
    "submission = generate_submission(filename, yhat, True)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
