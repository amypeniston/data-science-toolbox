{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering, Big Data, and Machine Learning on Google Cloud Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of internet connected devices continues to grow, the amount of data generated worldwide is becoming mind-bogglingly large. Due to this proliferation of information, it is more important than ever to be able to build applications that can derive insights from vast quantities of data in an automated fashion.\n",
    "\n",
    "The Google Cloud Platform (GCP) provides four core infrastructure components: underlying all applications is **security**; above this base are **compute power**, **storage** and **networking** tools; finally, atop these, are high level **big data and machine learning products** that abstract away difficult implementation work.\n",
    "\n",
    "#### The Big Data Ecosystem\n",
    "\n",
    "* Hadoop: the most popular MapReduce framework\n",
    "* Spark: general purpose framework for SQL, streaming, ML and more\n",
    "* Hive: datawarehousing system and query language\n",
    "* Pig: scripting language that can be compiled into Hadoop MapReduce jobs\n",
    "\n",
    "#### Compute Power\n",
    "\n",
    "Google's compute engine is an Infrastructure as a Service or IaaS solution that enables users to run virtual machines.\n",
    "\n",
    "Google trains machine learning algorithms on a vast network of data centers. Smaller, trained versions of these models are then deployed onto consumer hardware. You can access Google's AI research via pre-trained AI models that can be utilized out-of-the-box.\n",
    "\n",
    "As Moore's Law has slowed and the rate of compute performance has plateaued, one solution has been to build Application-Specific Chips (ASICs) to limit the power consumption of a chip. Google has created Tensor Processing Units (TPUs) with more memory and faster processors that are specifically optimized for machine learning workloads. TPUs in the cloud enable businesses to solve large, challenging problems in a way that would not otherwise have been possible.\n",
    "\n",
    "`Google Cloud Platform > Compute > Compute Engine > VM instances`\n",
    "\n",
    "An example process:\n",
    "\n",
    "* Spin up a VM\n",
    "* Perform processing\n",
    "* Stop the VM\n",
    "* Copy output into cloud storage\n",
    "* Serve files to end users\n",
    "\n",
    "#### Storage\n",
    "\n",
    "One major way that cloud computing differs from typical desktop computing is that compute and storage are independent. The size of the disks associated with a compute instance do not limit the amount of data that can be processed and stored. Rather, data is transferred via pipelines into a cloud storage solution, for example an elastic storage bucket. Google `gsutil` commands, via the Google Cloud SDK, provide a Unix-like syntax for copying files into buckets.\n",
    "\n",
    "Storage options:\n",
    "\n",
    "* Unstructured data? Cloud Storage\n",
    "* Structured, transactional data? Cloud SQL or Cloud Spanner (SQL-based retrieval) or Cloud Datastore (key-based retrieval)\n",
    "* Structured data requiring analytics? Cloud Bigtable (low latency) or BigQuery (higher latency)\n",
    "\n",
    "`Google Cloud Platform > Storage > Storage`\n",
    "\n",
    "`Google Cloud Platform > Storage > SQL`\n",
    "\n",
    "`Google Cloud Platform > Big Data > BigQuery`\n",
    "\n",
    "**Cloud SQL** is a transactional RDBMS that is optimized for more WRITES than READS; such relational databases are best suited for transactional updates on relatively small datasets. In contrast, BigQuery is a big data analytics warehouse for reporting READS. \n",
    "\n",
    "**Cloud Storage** is better suited for unstructured data that is accessed infrequently but may be used at a later time, for example imported from a bucket into a Hadoop cluster for analysis or read into BigQuery.\n",
    "\n",
    "**BigQuery** is a petabyte-scale, severless data warehouse complete with data analytics and accessible via web UI, REST API, command line and third-party tools. It is comprised of two services:  a fast SQL Query Engine and fully manged data storage. You can feed large datasets through machine learning algorithms or apply GIS functions directly within BigQuery. BigQuery also offers additional features such as support for arrays as data types as well as a special field type called RECORD, which is a STRUCT that can contain multiple associated fields. Also included with BigQuery are [public datasets](https://console.cloud.google.com/marketplace/browse?filter=solution-type:dataset&_ga=2.229760409.-449722783.1565046880) (both structured and unstructured) that are maintained by Google.\n",
    "\n",
    "**Cloud Dataprep** enables users to clean and transform data via a web UI. Variables can be inspected for the number of different categories or missing values. You can also create a data cleaning pipeline and apply it to streaming data via Dataflow.\n",
    "\n",
    "#### Networking\n",
    "\n",
    "Googleâ€™s private network is the largest in the world, comprised of thousands of miles of fiber optic cable providing petabit bisectional bandwidth. This network interconnects with the public Internet at many Edge points of presence worldwide. When a user accesses a Google resource, they are redirected to the location that will provide the lowest latency response.\n",
    "\n",
    "#### Security\n",
    "\n",
    "Google provides security for lower level systems such as physical hardware and data encryption that would otherwise be difficult for many businesses to manage on their own. Similarly, customizable user access controls in BigQuery enable pinpoint security for data and encryption keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Migrating Existing Setups to the Cloud\n",
    "\n",
    "An on-premises model using SparkML and Apache Hadoop clusters can be moved onto Google Cloud, using Cloud Dataproc to run machine-learning jobs and Cloud SQL (or one of the other storage options) as the RDBMS. Migrated jobs can be run on specialized, ephemeral clusters that only need to be active for the duration that the job is running. \n",
    "\n",
    "* Create a cluster\n",
    "* Submit jobs to cluster\n",
    "\n",
    "`Google Cloud Platform > Big Data > Dataproc`\n",
    "\n",
    "Fault-tolerant workloads, which can handle interruptions of individual VMs, may be candidates for Preemptible Virtual Machines (PVMs), which offer further cost-savings for the user.\n",
    "\n",
    "#### Big Data Pipelines\n",
    "\n",
    "Modern streaming pipelines must accommodate a wide variety of different data sources as well as significant data volume and velocity. One such example is amalgamating data from a network of IoT devices. **Cloud Pub/Sub** is a distributed messaging service that facilitates streaming pipelines by ingesting messages from publishers and outputting messages to subscribers. Each Pub/Sub instance is tagged to a specific topic. \n",
    "\n",
    "Apache Beam is a common solution for designing batch and streaming pipelines. Beam jobs are executed via Cloud Dataflow without having to explicitly manage compute and storage or worry about scaling. \n",
    "\n",
    "#### Machine Learning\n",
    "\n",
    "There are 3 options for doing machine learning on GCP. \n",
    "\n",
    "- BigQuery ML\n",
    "- Auto ML\n",
    "- Custom Keras models on TensorFlow\n",
    "\n",
    "**BigQuery ML** enables users to train machine learning models on data stored within BigQuery.\n",
    "\n",
    "**Google's AutoML** makes it easy to utilize high performance NASNet (Neural Architecture Search) algorithms that search for the optimal neural network architecture.\n",
    "\n",
    "Jupyter notebooks can be used to write and test custom machine learning models built using **Keras**.\n",
    "\n",
    "#### Data Visualization\n",
    "\n",
    "**Data Studio** enables users to visualize and highlight key insights; stock templates streamline the process of creating dashboard reports. This functionality can be accessed from within BigQuery."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
